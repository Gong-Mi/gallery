{
  "models": [
    {
      "name": "Gemma-3n-E2B-it",
      "modelId": "google/gemma-3n-E2B-it-litert-lm",
      "modelFile": "gemma-3n-E2B-it-int4.litertlm",
      "description": "[Gemma 3n E2B](https://ai.google.dev/gemma/docs/gemma-3n) 的端侧优化版本，已准备好通过 [LiteRT-LM](https://github.com/google-ai-edge/LiteRT-LM) 部署在 Android 上。支持文本、视觉和音频输入，上下文长度为 4096。建议在天玑 9300 等设备上尝试 NPU (NNAPI) 加速。",
      "sizeInBytes": 3655827456,
      "minDeviceMemoryInGb": 8,
      "commitHash": "ba9ca88da013b537b6ed38108be609b8db1c3a16",
      "llmSupportImage": true,
      "llmSupportAudio": true,
      "defaultConfig": {
        "topK": 64,
        "topP": 0.95,
        "temperature": 1.0,
        "maxTokens": 4096,
        "accelerators": "cpu,gpu,npu"
      },
      "taskTypes": ["llm_chat", "llm_prompt_lab", "llm_ask_image", "llm_ask_audio"],
      "bestForTaskTypes": ["llm_ask_image", "llm_ask_audio"]
    },
    {
      "name": "Gemma-3n-E4B-it",
      "modelId": "google/gemma-3n-E4B-it-litert-lm",
      "modelFile": "gemma-3n-E4B-it-int4.litertlm",
      "description": "[Gemma 3n E4B](https://ai.google.dev/gemma/docs/gemma-3n) 的端侧优化版本，已准备好通过 [LiteRT-LM](https://github.com/google-ai-edge/LiteRT-LM) 部署在 Android 上。支持文本、视觉和音频输入，上下文长度为 4096。建议在天玑 9300 等设备上尝试 NPU (NNAPI) 加速。",
      "sizeInBytes": 4919541760,
      "minDeviceMemoryInGb": 12,
      "commitHash": "297ed75955702dec3503e00c2c2ecbbf475300bc",
      "llmSupportImage": true,
      "llmSupportAudio": true,
      "defaultConfig": {
        "topK": 64,
        "topP": 0.95,
        "temperature": 1.0,
        "maxTokens": 4096,
        "accelerators": "cpu,gpu,npu"
      },
      "taskTypes": ["llm_chat", "llm_prompt_lab", "llm_ask_image", "llm_ask_audio"]
    },
    {
      "name": "Gemma3-1B-IT",
      "modelId": "litert-community/Gemma3-1B-IT",
      "modelFile": "gemma3-1b-it-int4.litertlm",
      "description": "[google/Gemma-3-1B-IT](https://huggingface.co/google/Gemma-3-1B-IT) 的 4-bit 量化变体，已准备好通过 [LiteRT-LM](https://github.com/google-ai-edge/LiteRT-LM) 部署在 Android 上。支持 NPU (NNAPI) 加速。",
      "sizeInBytes": 584417280,
      "minDeviceMemoryInGb": 6,
      "commitHash": "42d538a932e8d5b12e6b3b455f5572560bd60b2c",
      "defaultConfig": {
        "topK": 64,
        "topP": 0.95,
        "temperature": 1.0,
        "maxTokens": 1024,
        "accelerators": "gpu,cpu,npu"
      },
      "taskTypes": ["llm_chat", "llm_prompt_lab"],
      "bestForTaskTypes": ["llm_chat", "llm_prompt_lab"]
    },
    {
      "name": "Qwen2.5-1.5B-Instruct",
      "modelId": "litert-community/Qwen2.5-1.5B-Instruct",
      "modelFile": "Qwen2.5-1.5B-Instruct_multi-prefill-seq_q8_ekv4096.litertlm",
      "description": "[Qwen/Qwen2.5-1.5B-Instruct](https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct) 的变体，已准备好通过 [LiteRT-LM](https://github.com/google-ai-edge/LiteRT-LM) 部署在 Android 上。",
      "sizeInBytes": 1597931520,
      "minDeviceMemoryInGb": 6,
      "commitHash": "19edb84c69a0212f29a6ef17ba0d6f278b6a1614",
      "defaultConfig": {
        "topK": 20,
        "topP": 0.8,
        "temperature": 0.7,
        "maxTokens": 4096,
        "accelerators": "gpu,cpu,npu"
      },
      "taskTypes": ["llm_chat", "llm_prompt_lab"]
    },
    {
      "name": "Phi-4-mini-instruct",
      "modelId": "litert-community/Phi-4-mini-instruct",
      "modelFile": "Phi-4-mini-instruct_multi-prefill-seq_q8_ekv4096.litertlm",
      "description": "[microsoft/Phi-4-mini-instruct](https://huggingface.co/microsoft/Phi-4-mini-instruct) 的变体，已准备好通过 [LiteRT-LM](https://github.com/google-ai-edge/LiteRT-LM) 部署在 Android 上。",
      "sizeInBytes": 3910090752,
      "minDeviceMemoryInGb": 6,
      "commitHash": "054f4e2694a86f81a129a40596e08b8d74770a9d",
      "defaultConfig": {
        "topK": 64,
        "topP": 0.95,
        "temperature": 1.0,
        "maxTokens": 4096,
        "accelerators": "gpu,cpu,npu"
      },
      "taskTypes": ["llm_chat", "llm_prompt_lab"]
    },
    {
      "name": "DeepSeek-R1-Distill-Qwen-1.5B",
      "modelId": "litert-community/DeepSeek-R1-Distill-Qwen-1.5B",
      "modelFile": "DeepSeek-R1-Distill-Qwen-1.5B_multi-prefill-seq_q8_ekv4096.litertlm",
      "description": "[deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B) 的变体，已准备好通过 [LiteRT-LM](https://github.com/google-ai-edge/LiteRT-LM) 部署 in Android 上。",
      "sizeInBytes": 1833451520,
      "minDeviceMemoryInGb": 6,
      "commitHash": "e34bb88632342d1f9640bad579a45134eb1cf988",
      "defaultConfig": {
        "topK": 64,
        "topP": 0.95,
        "temperature": 1.0,
        "maxTokens": 4096,
        "accelerators": "gpu,cpu,npu"
      },
      "taskTypes": ["llm_chat", "llm_prompt_lab"]
    },
    {
      "name": "TinyGarden-270M",
      "modelId": "google/functiongemma-270m-it",
      "modelFile": "tiny_garden.litertlm",
      "description": "针对 Tiny Garden 游戏微调的 Function Gemma 270M 模型。",
      "sizeInBytes": 288440320,
      "minDeviceMemoryInGb": 6,
      "commitHash": "f54f8715e2b205f72c350f6efa748fd29fa19d98",
      "defaultConfig": {
        "topK": 64,
        "topP": 0.95,
        "temperature": 0.0,
        "maxTokens": 1024,
        "accelerators": "cpu,gpu,npu"
      },
      "taskTypes": [
        "llm_tiny_garden"
      ],
      "bestForTaskTypes": [
        "llm_tiny_garden"
      ]
    }
  ]
}